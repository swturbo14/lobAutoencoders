{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the original data\n",
    "message_org = pd.read_csv(\n",
    "    filepath_or_buffer='LOBSTER_SampleFile_AAPL_2012-06-21_5/AAPL_2012-06-21_34200000_57600000_message_5.csv',\n",
    "    names=['Time', 'Type', 'Order ID', 'Size', 'Price', 'Direction']\n",
    "    ).drop(['Time','Order ID'], axis=1)\n",
    "\n",
    "orderbook_org = pd.read_csv(\n",
    "    filepath_or_buffer='LOBSTER_SampleFile_AAPL_2012-06-21_5/AAPL_2012-06-21_34200000_57600000_orderbook_5.csv',\n",
    "    names=['A1P', 'A1V', 'B1P', 'B1V', 'A2P', 'A2V', 'B2P', 'B2V', 'A3P', 'A3V', 'B3P', 'B3V', 'A4P', 'A4V', 'B4P', 'B4V',\n",
    "           'A5P', 'A5V', 'B5P', 'B5V']\n",
    "           ).loc[:, ['A2P', 'A2V', 'A1P', 'A1V', 'B1P', 'B1V', 'B2P', 'B2V']]\n",
    "\n",
    "orderbook_org.drop_duplicates(inplace=True)\n",
    "message_org = message_org.loc[orderbook_org.index]\n",
    "orderbook_org.reset_index(inplace=True, drop=True)\n",
    "message_org.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LOB state, agent's cash, and inventory\n",
    "initial_cash = 1e6\n",
    "orderbook_org['Cash'] = initial_cash  # Initial cash in hand\n",
    "initial_inv = 1e4\n",
    "orderbook_org['Inventory'] = initial_inv   # Initial inventory\n",
    "\n",
    "execute_index = message_org['Type'] == 4\n",
    "cash_change = (- (message_org[execute_index]['Direction'] * \n",
    "                  message_org[execute_index]['Size'] * \n",
    "                  message_org[execute_index]['Price'] / 1e4)).cumsum()\n",
    "inventory_change = (message_org[execute_index]['Direction'] * \n",
    "                    message_org[execute_index]['Size']).cumsum()\n",
    "\n",
    "orderbook_org['Cash'] += cash_change \n",
    "orderbook_org['Inventory'] += inventory_change\n",
    "\n",
    "orderbook_org.loc[0,'Cash'] = initial_cash\n",
    "orderbook_org.loc[0,'Inventory'] = initial_inv\n",
    "orderbook_org.ffill(inplace=True)\n",
    "\n",
    "orderbook_org = pd.concat([message_org, orderbook_org],axis=1)\n",
    "\n",
    "del initial_cash, initial_inv, execute_index, cash_change, inventory_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize orderbook data and transform to tensor\n",
    "orderbook_norm = orderbook_org.copy()\n",
    "for column in ['Size', 'Price', 'A2P', 'A2V', 'A1P', 'A1V', 'B1P', 'B1V', 'B2P', 'B2V', 'Cash', 'Inventory']:\n",
    "    orderbook_norm[column] = (orderbook_norm[column] - orderbook_org[column].mean()) / orderbook_org[column].std()\n",
    "\n",
    "lob_data = torch.tensor(\n",
    "    orderbook_norm.to_numpy(),\n",
    "    dtype=torch.float32\n",
    ")\n",
    "\n",
    "# Placeholder for action data preparation\n",
    "# actions_data = torch.tensor(\n",
    "#     message_org.to_numpy(),\n",
    "#     dtype=torch.float32\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Autoencoder architecture\n",
    "class LOBEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, state_dim):\n",
    "        super(LOBEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, state_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "class LOBDecoder(nn.Module):\n",
    "    def __init__(self, state_dim, output_dim):  # action_dim,\n",
    "        super(LOBDecoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(state_dim, 64),  # + action_dim\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, s):  # ,u\n",
    "        # s = torch.cat((s, u), dim=1)\n",
    "        return self.decoder(s)\n",
    "\n",
    "class LOBPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, state_dim, output_dim):  # action_dim,\n",
    "        super(LOBPredictor, self).__init__()\n",
    "        self.encoder = LOBEncoder(input_dim, state_dim)\n",
    "        self.decoder = LOBDecoder(state_dim, output_dim)  # ,action_dim\n",
    "    \n",
    "    def forward(self, o):  # ,u\n",
    "        s = self.encoder(o)\n",
    "        o_next_pred = self.decoder(s)  # ,u\n",
    "        return o_next_pred\n",
    "\n",
    "# Example dimensions\n",
    "input_dim = lob_data.shape[1]  # Observation dimension\n",
    "state_dim = 8  # Agent state dimension\n",
    "# action_dim = 4  # Action dimension (Type, Size, Price, Direction)\n",
    "output_dim = lob_data.shape[1]  # Next observation dimension (same as input_dim)\n",
    "\n",
    "predictor = LOBPredictor(input_dim, state_dim, output_dim)  # ,action_dim\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 200\n",
    "batch_size = 1024\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(predictor.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 0.6594\n",
      "Epoch [2/200], Loss: 0.6321\n",
      "Epoch [3/200], Loss: 0.5388\n",
      "Epoch [4/200], Loss: 0.5100\n",
      "Epoch [5/200], Loss: 0.4319\n",
      "Epoch [6/200], Loss: 0.4473\n",
      "Epoch [7/200], Loss: 0.4192\n",
      "Epoch [8/200], Loss: 0.4141\n",
      "Epoch [9/200], Loss: 0.4251\n",
      "Epoch [10/200], Loss: 0.4036\n",
      "Epoch [11/200], Loss: 0.4153\n",
      "Epoch [12/200], Loss: 0.3970\n",
      "Epoch [13/200], Loss: 0.4298\n",
      "Epoch [14/200], Loss: 0.3868\n",
      "Epoch [15/200], Loss: 0.3722\n",
      "Epoch [16/200], Loss: 0.3717\n",
      "Epoch [17/200], Loss: 0.3766\n",
      "Epoch [18/200], Loss: 0.3833\n",
      "Epoch [19/200], Loss: 0.3892\n",
      "Epoch [20/200], Loss: 0.3732\n",
      "Epoch [21/200], Loss: 0.3686\n",
      "Epoch [22/200], Loss: 0.3636\n",
      "Epoch [23/200], Loss: 0.3628\n",
      "Epoch [24/200], Loss: 0.3626\n",
      "Epoch [25/200], Loss: 0.3662\n",
      "Epoch [26/200], Loss: 0.3647\n",
      "Epoch [27/200], Loss: 0.4014\n",
      "Epoch [28/200], Loss: 0.3701\n",
      "Epoch [29/200], Loss: 0.3788\n",
      "Epoch [30/200], Loss: 0.3589\n",
      "Epoch [31/200], Loss: 0.3954\n",
      "Epoch [32/200], Loss: 0.3606\n",
      "Epoch [33/200], Loss: 0.3741\n",
      "Epoch [34/200], Loss: 0.3590\n",
      "Epoch [35/200], Loss: 0.3755\n",
      "Epoch [36/200], Loss: 0.3577\n",
      "Epoch [37/200], Loss: 0.3757\n",
      "Epoch [38/200], Loss: 0.3585\n",
      "Epoch [39/200], Loss: 0.3899\n",
      "Epoch [40/200], Loss: 0.3592\n",
      "Epoch [41/200], Loss: 0.3805\n",
      "Epoch [42/200], Loss: 0.3605\n",
      "Epoch [43/200], Loss: 0.3799\n",
      "Epoch [44/200], Loss: 0.3592\n",
      "Epoch [45/200], Loss: 0.3731\n",
      "Epoch [46/200], Loss: 0.3649\n",
      "Epoch [47/200], Loss: 0.3724\n",
      "Epoch [48/200], Loss: 0.3635\n",
      "Epoch [49/200], Loss: 0.3692\n",
      "Epoch [50/200], Loss: 0.3654\n",
      "Epoch [51/200], Loss: 0.3721\n",
      "Epoch [52/200], Loss: 0.3655\n",
      "Epoch [53/200], Loss: 0.3676\n",
      "Epoch [54/200], Loss: 0.3651\n",
      "Epoch [55/200], Loss: 0.3706\n",
      "Epoch [56/200], Loss: 0.3841\n",
      "Epoch [57/200], Loss: 0.3651\n",
      "Epoch [58/200], Loss: 0.3809\n",
      "Epoch [59/200], Loss: 0.3553\n",
      "Epoch [60/200], Loss: 0.3604\n",
      "Epoch [61/200], Loss: 0.3538\n",
      "Epoch [62/200], Loss: 0.3696\n",
      "Epoch [63/200], Loss: 0.3545\n",
      "Epoch [64/200], Loss: 0.3590\n",
      "Epoch [65/200], Loss: 0.3619\n",
      "Epoch [66/200], Loss: 0.3631\n",
      "Epoch [67/200], Loss: 0.3607\n",
      "Epoch [68/200], Loss: 0.3657\n",
      "Epoch [69/200], Loss: 0.3595\n",
      "Epoch [70/200], Loss: 0.3593\n",
      "Epoch [71/200], Loss: 0.3578\n",
      "Epoch [72/200], Loss: 0.3583\n",
      "Epoch [73/200], Loss: 0.3576\n",
      "Epoch [74/200], Loss: 0.3585\n",
      "Epoch [75/200], Loss: 0.3542\n",
      "Epoch [76/200], Loss: 0.3534\n",
      "Epoch [77/200], Loss: 0.3567\n",
      "Epoch [78/200], Loss: 0.3618\n",
      "Epoch [79/200], Loss: 0.3590\n",
      "Epoch [80/200], Loss: 0.3661\n",
      "Epoch [81/200], Loss: 0.3565\n",
      "Epoch [82/200], Loss: 0.3683\n",
      "Epoch [83/200], Loss: 0.3600\n",
      "Epoch [84/200], Loss: 0.3801\n",
      "Epoch [85/200], Loss: 0.3537\n",
      "Epoch [86/200], Loss: 0.3597\n",
      "Epoch [87/200], Loss: 0.3614\n",
      "Epoch [88/200], Loss: 0.3679\n",
      "Epoch [89/200], Loss: 0.3544\n",
      "Epoch [90/200], Loss: 0.3635\n",
      "Epoch [91/200], Loss: 0.3548\n",
      "Epoch [92/200], Loss: 0.3588\n",
      "Epoch [93/200], Loss: 0.3487\n",
      "Epoch [94/200], Loss: 0.3503\n",
      "Epoch [95/200], Loss: 0.3519\n",
      "Epoch [96/200], Loss: 0.3535\n",
      "Epoch [97/200], Loss: 0.3490\n",
      "Epoch [98/200], Loss: 0.3617\n",
      "Epoch [99/200], Loss: 0.3542\n",
      "Epoch [100/200], Loss: 0.3744\n",
      "Epoch [101/200], Loss: 0.3566\n",
      "Epoch [102/200], Loss: 0.3552\n",
      "Epoch [103/200], Loss: 0.3537\n",
      "Epoch [104/200], Loss: 0.3619\n",
      "Epoch [105/200], Loss: 0.3566\n",
      "Epoch [106/200], Loss: 0.3512\n",
      "Epoch [107/200], Loss: 0.3485\n",
      "Epoch [108/200], Loss: 0.3477\n",
      "Epoch [109/200], Loss: 0.3573\n",
      "Epoch [110/200], Loss: 0.3652\n",
      "Epoch [111/200], Loss: 0.3474\n",
      "Epoch [112/200], Loss: 0.3489\n",
      "Epoch [113/200], Loss: 0.3478\n",
      "Epoch [114/200], Loss: 0.3485\n",
      "Epoch [115/200], Loss: 0.3507\n",
      "Epoch [116/200], Loss: 0.3516\n",
      "Epoch [117/200], Loss: 0.3505\n",
      "Epoch [118/200], Loss: 0.3704\n",
      "Epoch [119/200], Loss: 0.3520\n",
      "Epoch [120/200], Loss: 0.3506\n",
      "Epoch [121/200], Loss: 0.3515\n",
      "Epoch [122/200], Loss: 0.3524\n",
      "Epoch [123/200], Loss: 0.3486\n",
      "Epoch [124/200], Loss: 0.3488\n",
      "Epoch [125/200], Loss: 0.3537\n",
      "Epoch [126/200], Loss: 0.3557\n",
      "Epoch [127/200], Loss: 0.3470\n",
      "Epoch [128/200], Loss: 0.3457\n",
      "Epoch [129/200], Loss: 0.3429\n",
      "Epoch [130/200], Loss: 0.3449\n",
      "Epoch [131/200], Loss: 0.3448\n",
      "Epoch [132/200], Loss: 0.3501\n",
      "Epoch [133/200], Loss: 0.3437\n",
      "Epoch [134/200], Loss: 0.3575\n",
      "Epoch [135/200], Loss: 0.3519\n",
      "Epoch [136/200], Loss: 0.3565\n",
      "Epoch [137/200], Loss: 0.3550\n",
      "Epoch [138/200], Loss: 0.3528\n",
      "Epoch [139/200], Loss: 0.3464\n",
      "Epoch [140/200], Loss: 0.3458\n",
      "Epoch [141/200], Loss: 0.3401\n",
      "Epoch [142/200], Loss: 0.3550\n",
      "Epoch [143/200], Loss: 0.3559\n",
      "Epoch [144/200], Loss: 0.3572\n",
      "Epoch [145/200], Loss: 0.3549\n",
      "Epoch [146/200], Loss: 0.3503\n",
      "Epoch [147/200], Loss: 0.3480\n",
      "Epoch [148/200], Loss: 0.3458\n",
      "Epoch [149/200], Loss: 0.3409\n",
      "Epoch [150/200], Loss: 0.3410\n",
      "Epoch [151/200], Loss: 0.3416\n",
      "Epoch [152/200], Loss: 0.3452\n",
      "Epoch [153/200], Loss: 0.3454\n",
      "Epoch [154/200], Loss: 0.3533\n",
      "Epoch [155/200], Loss: 0.3441\n",
      "Epoch [156/200], Loss: 0.3534\n",
      "Epoch [157/200], Loss: 0.3434\n",
      "Epoch [158/200], Loss: 0.3494\n",
      "Epoch [159/200], Loss: 0.3402\n",
      "Epoch [160/200], Loss: 0.3497\n",
      "Epoch [161/200], Loss: 0.3383\n",
      "Epoch [162/200], Loss: 0.3430\n",
      "Epoch [163/200], Loss: 0.3387\n",
      "Epoch [164/200], Loss: 0.3455\n",
      "Epoch [165/200], Loss: 0.3425\n",
      "Epoch [166/200], Loss: 0.3453\n",
      "Epoch [167/200], Loss: 0.3424\n",
      "Epoch [168/200], Loss: 0.3391\n",
      "Epoch [169/200], Loss: 0.3400\n",
      "Epoch [170/200], Loss: 0.3448\n",
      "Epoch [171/200], Loss: 0.3413\n",
      "Epoch [172/200], Loss: 0.3448\n",
      "Epoch [173/200], Loss: 0.3403\n",
      "Epoch [174/200], Loss: 0.3493\n",
      "Epoch [175/200], Loss: 0.3563\n",
      "Epoch [176/200], Loss: 0.3576\n",
      "Epoch [177/200], Loss: 0.3403\n",
      "Epoch [178/200], Loss: 0.3409\n",
      "Epoch [179/200], Loss: 0.3382\n",
      "Epoch [180/200], Loss: 0.3460\n",
      "Epoch [181/200], Loss: 0.3437\n",
      "Epoch [182/200], Loss: 0.3537\n",
      "Epoch [183/200], Loss: 0.3493\n",
      "Epoch [184/200], Loss: 0.3389\n",
      "Epoch [185/200], Loss: 0.3351\n",
      "Epoch [186/200], Loss: 0.3360\n",
      "Epoch [187/200], Loss: 0.3340\n",
      "Epoch [188/200], Loss: 0.3381\n",
      "Epoch [189/200], Loss: 0.3361\n",
      "Epoch [190/200], Loss: 0.3405\n",
      "Epoch [191/200], Loss: 0.3424\n",
      "Epoch [192/200], Loss: 0.3447\n",
      "Epoch [193/200], Loss: 0.3384\n",
      "Epoch [194/200], Loss: 0.3446\n",
      "Epoch [195/200], Loss: 0.3377\n",
      "Epoch [196/200], Loss: 0.3434\n",
      "Epoch [197/200], Loss: 0.3358\n",
      "Epoch [198/200], Loss: 0.3456\n",
      "Epoch [199/200], Loss: 0.3423\n",
      "Epoch [200/200], Loss: 0.3588\n"
     ]
    }
   ],
   "source": [
    "# Prepare input (observations), actions, and target (next observations)\n",
    "observations = lob_data[:-1, :]  # All except the last time step\n",
    "# actions = actions_data[:-1, :]  # Corresponding actions for each observation\n",
    "next_observations = lob_data[1:, :]  # All except the first time step\n",
    "\n",
    "# DataLoader for batching\n",
    "dataset = torch.utils.data.TensorDataset(observations, next_observations)  # ,actions\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for obs, next_obs in train_loader:  # ,act\n",
    "        # Forward pass\n",
    "        predicted_next_obs = predictor(obs)  # ,act\n",
    "        loss = criterion(predicted_next_obs, next_obs)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation and Visualization\n",
    "# Get a batch of data\n",
    "data_iter = iter(train_loader)\n",
    "obs_data, next_obs_data = next(data_iter)  # ,act_data\n",
    "\n",
    "# Predict the next observation using the predictor\n",
    "with torch.no_grad():\n",
    "    predicted_next_obs_data = predictor(obs_data)  # ,act_data\n",
    "\n",
    "# Denormalize the data for visualization\n",
    "next_obs_data = pd.DataFrame(next_obs_data.numpy(), columns=list(orderbook_org.columns))\n",
    "predicted_next_obs_data = pd.DataFrame(predicted_next_obs_data.numpy(), columns=list(orderbook_org.columns))\n",
    "\n",
    "for column in ['Size', 'Price', 'A2P', 'A2V', 'A1P', 'A1V', 'B1P', 'B1V', 'B2P', 'B2V', 'Cash', 'Inventory']:\n",
    "    next_obs_data[column] = next_obs_data[column] * orderbook_org[column].std() + orderbook_org[column].mean()\n",
    "    predicted_next_obs_data[column] = predicted_next_obs_data[column] * orderbook_org[column].std() + orderbook_org[column].mean()\n",
    "\n",
    "# Visualization (commented out for non-interactive environments)\n",
    "# import matplotlib.pyplot as plt\n",
    "# # Plot next observation (target) vs predicted next observation\n",
    "# fig, ax = plt.subplots(2, 1, figsize=(10, 5))\n",
    "# # Plot next observation (target)\n",
    "# ax[0].plot(next_obs_data.values.flatten(), label='Next Observation (Target)')\n",
    "# ax[0].set_title('Next Observation (Target)')\n",
    "# # Plot predicted next observation\n",
    "# ax[1].plot(predicted_next_obs_data.values.flatten(), label='Predicted Next Observation')\n",
    "# ax[1].set_title('Predicted Next Observation')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Price</th>\n",
       "      <th>Direction</th>\n",
       "      <th>A2P</th>\n",
       "      <th>A2V</th>\n",
       "      <th>A1P</th>\n",
       "      <th>A1V</th>\n",
       "      <th>B1P</th>\n",
       "      <th>B1V</th>\n",
       "      <th>B2P</th>\n",
       "      <th>B2V</th>\n",
       "      <th>Cash</th>\n",
       "      <th>Inventory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5853200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5859800.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>5859400.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>5853300.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5853200.0</td>\n",
       "      <td>18.000015</td>\n",
       "      <td>999999.875</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5859100.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5859400.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>5859100.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5853300.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5853200.0</td>\n",
       "      <td>18.000015</td>\n",
       "      <td>999999.875</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5859200.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5859200.0</td>\n",
       "      <td>18.000008</td>\n",
       "      <td>5859100.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5853300.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5853200.0</td>\n",
       "      <td>18.000015</td>\n",
       "      <td>999999.875</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5853200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5859200.0</td>\n",
       "      <td>18.000008</td>\n",
       "      <td>5859100.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5853300.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5853000.0</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>999999.875</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5859100.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5859300.0</td>\n",
       "      <td>118.000008</td>\n",
       "      <td>5859200.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5853300.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5853000.0</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>999999.875</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5859300.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5859300.0</td>\n",
       "      <td>100.000015</td>\n",
       "      <td>5859200.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5853300.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5853000.0</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>999999.875</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5859200.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5859400.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>5859300.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5853300.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5853000.0</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>999999.875</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5853600.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5859400.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>5859300.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5853600.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5853300.0</td>\n",
       "      <td>18.000015</td>\n",
       "      <td>999999.875</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5853500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5859400.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>5859300.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5853600.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5853500.0</td>\n",
       "      <td>18.000015</td>\n",
       "      <td>999999.875</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.000004</td>\n",
       "      <td>5857300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5859400.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>5859300.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5857300.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5853600.0</td>\n",
       "      <td>18.000015</td>\n",
       "      <td>999999.875</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type       Size      Price  Direction        A2P         A2V        A1P  \\\n",
       "0   1.0  18.000000  5853200.0        1.0  5859800.0  200.000000  5859400.0   \n",
       "1   1.0  18.000000  5859100.0       -1.0  5859400.0  200.000000  5859100.0   \n",
       "2   1.0  18.000000  5859200.0       -1.0  5859200.0   18.000008  5859100.0   \n",
       "3   3.0  18.000000  5853200.0        1.0  5859200.0   18.000008  5859100.0   \n",
       "4   3.0  18.000000  5859100.0       -1.0  5859300.0  118.000008  5859200.0   \n",
       "5   3.0  18.000000  5859300.0       -1.0  5859300.0  100.000015  5859200.0   \n",
       "6   3.0  18.000000  5859200.0       -1.0  5859400.0  200.000000  5859300.0   \n",
       "7   1.0  18.000000  5853600.0        1.0  5859400.0  200.000000  5859300.0   \n",
       "8   1.0  18.000000  5853500.0        1.0  5859400.0  200.000000  5859300.0   \n",
       "9   1.0  20.000004  5857300.0        1.0  5859400.0  200.000000  5859300.0   \n",
       "\n",
       "     A1V        B1P   B1V        B2P         B2V        Cash  Inventory  \n",
       "0  200.0  5853300.0  18.0  5853200.0   18.000015  999999.875    10000.0  \n",
       "1   18.0  5853300.0  18.0  5853200.0   18.000015  999999.875    10000.0  \n",
       "2   18.0  5853300.0  18.0  5853200.0   18.000015  999999.875    10000.0  \n",
       "3   18.0  5853300.0  18.0  5853000.0  150.000000  999999.875    10000.0  \n",
       "4   18.0  5853300.0  18.0  5853000.0  150.000000  999999.875    10000.0  \n",
       "5   18.0  5853300.0  18.0  5853000.0  150.000000  999999.875    10000.0  \n",
       "6  100.0  5853300.0  18.0  5853000.0  150.000000  999999.875    10000.0  \n",
       "7  100.0  5853600.0  18.0  5853300.0   18.000015  999999.875    10000.0  \n",
       "8  100.0  5853600.0  18.0  5853500.0   18.000015  999999.875    10000.0  \n",
       "9  100.0  5857300.0  20.0  5853600.0   18.000015  999999.875    10000.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_obs_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Price</th>\n",
       "      <th>Direction</th>\n",
       "      <th>A2P</th>\n",
       "      <th>A2V</th>\n",
       "      <th>A1P</th>\n",
       "      <th>A1V</th>\n",
       "      <th>B1P</th>\n",
       "      <th>B1V</th>\n",
       "      <th>B2P</th>\n",
       "      <th>B2V</th>\n",
       "      <th>Cash</th>\n",
       "      <th>Inventory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.208879</td>\n",
       "      <td>65.776443</td>\n",
       "      <td>5855409.0</td>\n",
       "      <td>0.419337</td>\n",
       "      <td>5858183.5</td>\n",
       "      <td>104.298592</td>\n",
       "      <td>5857490.5</td>\n",
       "      <td>188.888184</td>\n",
       "      <td>5854522.5</td>\n",
       "      <td>57.072754</td>\n",
       "      <td>5854189.5</td>\n",
       "      <td>131.437729</td>\n",
       "      <td>1647858.875</td>\n",
       "      <td>9171.865234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.203244</td>\n",
       "      <td>61.185112</td>\n",
       "      <td>5854856.0</td>\n",
       "      <td>0.426575</td>\n",
       "      <td>5857645.0</td>\n",
       "      <td>101.953720</td>\n",
       "      <td>5857010.5</td>\n",
       "      <td>200.677460</td>\n",
       "      <td>5853909.0</td>\n",
       "      <td>31.210205</td>\n",
       "      <td>5853615.5</td>\n",
       "      <td>99.275055</td>\n",
       "      <td>1336266.625</td>\n",
       "      <td>9911.882812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.230187</td>\n",
       "      <td>45.088951</td>\n",
       "      <td>5857642.0</td>\n",
       "      <td>-0.305384</td>\n",
       "      <td>5859181.5</td>\n",
       "      <td>63.849068</td>\n",
       "      <td>5858943.0</td>\n",
       "      <td>18.775482</td>\n",
       "      <td>5855649.5</td>\n",
       "      <td>31.570694</td>\n",
       "      <td>5855317.0</td>\n",
       "      <td>131.716263</td>\n",
       "      <td>1940450.875</td>\n",
       "      <td>8224.232422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.276087</td>\n",
       "      <td>32.153458</td>\n",
       "      <td>5857398.0</td>\n",
       "      <td>-0.358538</td>\n",
       "      <td>5858546.5</td>\n",
       "      <td>10.955643</td>\n",
       "      <td>5858861.5</td>\n",
       "      <td>-11.916550</td>\n",
       "      <td>5855326.5</td>\n",
       "      <td>72.170029</td>\n",
       "      <td>5855076.0</td>\n",
       "      <td>192.682800</td>\n",
       "      <td>2107776.000</td>\n",
       "      <td>7786.164062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.656815</td>\n",
       "      <td>34.892467</td>\n",
       "      <td>5856111.5</td>\n",
       "      <td>0.316319</td>\n",
       "      <td>5857998.0</td>\n",
       "      <td>4.302826</td>\n",
       "      <td>5857900.5</td>\n",
       "      <td>14.694473</td>\n",
       "      <td>5854874.5</td>\n",
       "      <td>72.781281</td>\n",
       "      <td>5854530.0</td>\n",
       "      <td>182.284088</td>\n",
       "      <td>960680.375</td>\n",
       "      <td>9872.416016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.603282</td>\n",
       "      <td>44.189919</td>\n",
       "      <td>5856129.0</td>\n",
       "      <td>-0.602271</td>\n",
       "      <td>5856877.0</td>\n",
       "      <td>58.937805</td>\n",
       "      <td>5856688.0</td>\n",
       "      <td>26.926727</td>\n",
       "      <td>5854205.0</td>\n",
       "      <td>66.442596</td>\n",
       "      <td>5853507.0</td>\n",
       "      <td>226.530273</td>\n",
       "      <td>1286169.875</td>\n",
       "      <td>9402.919922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.647295</td>\n",
       "      <td>41.829876</td>\n",
       "      <td>5856073.5</td>\n",
       "      <td>-0.612603</td>\n",
       "      <td>5856773.0</td>\n",
       "      <td>54.986298</td>\n",
       "      <td>5856628.0</td>\n",
       "      <td>22.759575</td>\n",
       "      <td>5854166.5</td>\n",
       "      <td>69.211823</td>\n",
       "      <td>5853441.0</td>\n",
       "      <td>234.286667</td>\n",
       "      <td>1067542.125</td>\n",
       "      <td>9763.589844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.294078</td>\n",
       "      <td>59.929260</td>\n",
       "      <td>5857052.5</td>\n",
       "      <td>-0.292061</td>\n",
       "      <td>5858614.5</td>\n",
       "      <td>98.145401</td>\n",
       "      <td>5858026.5</td>\n",
       "      <td>55.150826</td>\n",
       "      <td>5855267.0</td>\n",
       "      <td>48.687637</td>\n",
       "      <td>5854726.5</td>\n",
       "      <td>183.619171</td>\n",
       "      <td>1718338.125</td>\n",
       "      <td>8776.001953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.242853</td>\n",
       "      <td>59.487518</td>\n",
       "      <td>5855772.0</td>\n",
       "      <td>0.403244</td>\n",
       "      <td>5858409.5</td>\n",
       "      <td>92.454849</td>\n",
       "      <td>5857790.5</td>\n",
       "      <td>135.750061</td>\n",
       "      <td>5854667.5</td>\n",
       "      <td>34.097260</td>\n",
       "      <td>5854342.0</td>\n",
       "      <td>103.778664</td>\n",
       "      <td>1663115.125</td>\n",
       "      <td>9340.094727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.249893</td>\n",
       "      <td>59.697388</td>\n",
       "      <td>5855744.0</td>\n",
       "      <td>0.403932</td>\n",
       "      <td>5858374.0</td>\n",
       "      <td>91.993561</td>\n",
       "      <td>5857766.5</td>\n",
       "      <td>135.591354</td>\n",
       "      <td>5854645.5</td>\n",
       "      <td>34.599594</td>\n",
       "      <td>5854316.5</td>\n",
       "      <td>104.001938</td>\n",
       "      <td>1625157.375</td>\n",
       "      <td>9406.420898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Type       Size      Price  Direction        A2P         A2V  \\\n",
       "0  1.208879  65.776443  5855409.0   0.419337  5858183.5  104.298592   \n",
       "1  1.203244  61.185112  5854856.0   0.426575  5857645.0  101.953720   \n",
       "2  1.230187  45.088951  5857642.0  -0.305384  5859181.5   63.849068   \n",
       "3  1.276087  32.153458  5857398.0  -0.358538  5858546.5   10.955643   \n",
       "4  1.656815  34.892467  5856111.5   0.316319  5857998.0    4.302826   \n",
       "5  1.603282  44.189919  5856129.0  -0.602271  5856877.0   58.937805   \n",
       "6  1.647295  41.829876  5856073.5  -0.612603  5856773.0   54.986298   \n",
       "7  1.294078  59.929260  5857052.5  -0.292061  5858614.5   98.145401   \n",
       "8  1.242853  59.487518  5855772.0   0.403244  5858409.5   92.454849   \n",
       "9  1.249893  59.697388  5855744.0   0.403932  5858374.0   91.993561   \n",
       "\n",
       "         A1P         A1V        B1P        B1V        B2P         B2V  \\\n",
       "0  5857490.5  188.888184  5854522.5  57.072754  5854189.5  131.437729   \n",
       "1  5857010.5  200.677460  5853909.0  31.210205  5853615.5   99.275055   \n",
       "2  5858943.0   18.775482  5855649.5  31.570694  5855317.0  131.716263   \n",
       "3  5858861.5  -11.916550  5855326.5  72.170029  5855076.0  192.682800   \n",
       "4  5857900.5   14.694473  5854874.5  72.781281  5854530.0  182.284088   \n",
       "5  5856688.0   26.926727  5854205.0  66.442596  5853507.0  226.530273   \n",
       "6  5856628.0   22.759575  5854166.5  69.211823  5853441.0  234.286667   \n",
       "7  5858026.5   55.150826  5855267.0  48.687637  5854726.5  183.619171   \n",
       "8  5857790.5  135.750061  5854667.5  34.097260  5854342.0  103.778664   \n",
       "9  5857766.5  135.591354  5854645.5  34.599594  5854316.5  104.001938   \n",
       "\n",
       "          Cash    Inventory  \n",
       "0  1647858.875  9171.865234  \n",
       "1  1336266.625  9911.882812  \n",
       "2  1940450.875  8224.232422  \n",
       "3  2107776.000  7786.164062  \n",
       "4   960680.375  9872.416016  \n",
       "5  1286169.875  9402.919922  \n",
       "6  1067542.125  9763.589844  \n",
       "7  1718338.125  8776.001953  \n",
       "8  1663115.125  9340.094727  \n",
       "9  1625157.375  9406.420898  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_next_obs_data.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
